<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Remotely Sensed Data Processing and Analysis: QGIS Methods - 5&nbsp; Supervised Satellite Image Classification for Urban Land Cover Mapping</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Hands-on_05.html" rel="next">
<link href="./Hands-on_03.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervised Satellite Image Classification for Urban Land Cover Mapping</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Remotely Sensed Data Processing and Analysis: QGIS Methods</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Hands-on_01.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Acquiring Landsat 8 Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Hands-on_02.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Acquiring Sentinel-2 Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Hands-on_03.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Processing and Visualising Landsat 8 Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Hands-on_04.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervised Satellite Image Classification for Urban Land Cover Mapping</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Hands-on_05.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Unsupervised Satellite Image Classification for Urban Land Cover Mapping</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"> <span class="header-section-number">5.1</span> Overview</a></li>
  <li><a href="#selecting-the-study-area" id="toc-selecting-the-study-area" class="nav-link" data-scroll-target="#selecting-the-study-area"> <span class="header-section-number">5.2</span> Selecting the study area</a></li>
  <li><a href="#semi-automatic-classification-plugin-scp" id="toc-semi-automatic-classification-plugin-scp" class="nav-link" data-scroll-target="#semi-automatic-classification-plugin-scp"> <span class="header-section-number">5.3</span> Semi-automatic classification Plugin (SCP)</a></li>
  <li><a href="#supervised-classification" id="toc-supervised-classification" class="nav-link" data-scroll-target="#supervised-classification"> <span class="header-section-number">5.4</span> Supervised Classification</a>
  <ul class="collapse">
  <li><a href="#defining-the-land-cover-scheme" id="toc-defining-the-land-cover-scheme" class="nav-link" data-scroll-target="#defining-the-land-cover-scheme"> <span class="header-section-number">5.4.1</span> Defining the land cover scheme</a></li>
  <li><a href="#creating-colour-composite-images" id="toc-creating-colour-composite-images" class="nav-link" data-scroll-target="#creating-colour-composite-images"> <span class="header-section-number">5.4.2</span> Creating Colour Composite Images</a></li>
  <li><a href="#creating-a-band-set" id="toc-creating-a-band-set" class="nav-link" data-scroll-target="#creating-a-band-set"> <span class="header-section-number">5.4.3</span> Creating a Band set</a></li>
  <li><a href="#digitsing-training-samples" id="toc-digitsing-training-samples" class="nav-link" data-scroll-target="#digitsing-training-samples"> <span class="header-section-number">5.4.4</span> Digitsing training samples</a></li>
  <li><a href="#assessing-the-spectral-signatures" id="toc-assessing-the-spectral-signatures" class="nav-link" data-scroll-target="#assessing-the-spectral-signatures"> <span class="header-section-number">5.4.5</span> Assessing the Spectral Signatures</a></li>
  <li><a href="#creating-a-classification-preview" id="toc-creating-a-classification-preview" class="nav-link" data-scroll-target="#creating-a-classification-preview"> <span class="header-section-number">5.4.6</span> Creating a Classification Preview</a></li>
  <li><a href="#generating-the-classification-output" id="toc-generating-the-classification-output" class="nav-link" data-scroll-target="#generating-the-classification-output"> <span class="header-section-number">5.4.7</span> Generating the Classification Output</a></li>
  <li><a href="#assessing-the-classification-accuracy" id="toc-assessing-the-classification-accuracy" class="nav-link" data-scroll-target="#assessing-the-classification-accuracy"> <span class="header-section-number">5.4.8</span> Assessing the classification accuracy</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"> <span class="header-section-number">5.5</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervised Satellite Image Classification for Urban Land Cover Mapping</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="overview" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">5.1</span> Overview</h2>
<p>In this chapter, you will gain hands-on experience on using QGIS and Semi-automatic classification Plugin (SCP) to perform supervised satellite image classification for urban land cover classification. It is a continuation of Chapter 3 and 4.</p>
<p>By the end of this chapter, you will acquire the skills to:</p>
<ul>
<li>preparing land cover scheme for supervised classification,</li>
<li>extracting sub-scene for classification,</li>
<li>digitising ROIs both for training and testing purposes,</li>
<li>assessing the spectral signatures of samples,</li>
<li>creating a classification preview,</li>
<li>generating the classification output,</li>
<li>assessing the classification accuracy.</li>
</ul>
</section>
<section id="selecting-the-study-area" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="selecting-the-study-area"><span class="header-section-number">5.2</span> Selecting the study area</h2>
<p>In this hands-on exercise, Sentinel-2 data of Singapore taken on 2020/01/26 (ID: S2A_MSIL1C_20200126T032011_N0208_R118_T48NUG_20200126T061348) will be used. The data can be downloaded from the Copernicus Open Access Hub website by click on this <a href="https://scihub.copernicus.eu/dhus/#/home">url</a>. You can find a step-by-step guide on how to download data from the Copernicus Open Access Hub in <a href="https://qgis4rdpa.netlify.app/hands-on_02">Chapter 3: Acquiring Sentinel-2 Data</a> of this workbook.</p>
<p>For the purpose of this hands-on exercise, a sub-scene of the data as shown in the figure below will be used.</p>
<p><img src="img04/image1.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, extract a study area similar to the screenshot below.</p>
</blockquote>
<p>The study area comprises of Choa Chu Kang, Bukit Panjang and Sungei Kadut planning areas. At the east of the study area is the Central Water Catchment whereby Singapore Zoo, River Safari and Night Safari sites can be seen clearly. Notice that the selected area is free of cloud cover which is very idea for image analysis. Otherwise, you have to use a cloud mask.</p>
</section>
<section id="semi-automatic-classification-plugin-scp" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="semi-automatic-classification-plugin-scp"><span class="header-section-number">5.3</span> Semi-automatic classification Plugin (SCP)</h2>
<p>In this hands-on exercise, SCP will be used. If you have yet to install SCP, follow the instruction provided by <a href="file:///D:/tskam/QGIS4RDPA/_book/Hands-on_03.html#installing-semi-automatic-classification-plugin">4.2 Installing Semi-Automatic Classification Plugin</a> of this workbook to install SCP.</p>
</section>
<section id="supervised-classification" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="supervised-classification"><span class="header-section-number">5.4</span> Supervised Classification</h2>
<p>The method of classification that you will attempt in this hands-on exercise is called supervised classification. This is a type of classification in which the analyst trains the system to identify spectral classes based on samples of pixels taken from the image. Adequate samples are to be used for each land cover class. Each class should be spectrally different from one another. Samples are made by creating a polygon in representative pixels from a class, then loading those pixels’ information as a signature. After samples have been taken for each land cover class, their separability is to be assessed by observing the signatures on a figure plotting wavelength vs.&nbsp;reflectance value. Samples may need to be refined based on that outcome. The final product of an image classification is a 1 band raster image with land cover types represented as different classes. Figure below shows a typical process of supervised classification.</p>
<p><img src="img04/image2.jpg" class="img-fluid" width="468"></p>
<section id="defining-the-land-cover-scheme" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="defining-the-land-cover-scheme"><span class="header-section-number">5.4.1</span> Defining the land cover scheme</h3>
<p>For the purpose of this study, nine land cover type will be classified, they are:</p>
<ol type="1">
<li><p>Water body: sea, coastal water, strait etc</p></li>
<li><p>Inland water: lakes, reservoirs, channels, etc.</p></li>
<li><p>Bare land: open lands</p></li>
<li><p>Natural and semi-natural vegetation</p></li>
<li><p>Managed vegetation: grass lands, parks, trees etc</p></li>
<li><p>Built-up 1: high-density buildings</p></li>
<li><p>Built-up 2: medium density buildings</p></li>
<li><p>Built-up 3: low density buildigns</p></li>
<li><p>Impervious surfaces:</p></li>
</ol>
</section>
<section id="creating-colour-composite-images" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="creating-colour-composite-images"><span class="header-section-number">5.4.2</span> Creating Colour Composite Images</h3>
<p>It is always a best practice to create colour composite images of the study area and use these images to assist you in the the selection and digitising of training and test vector data sets.</p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, create the following colour composite images.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img04/image1.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">A true colour composite of the study area</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img04/image3.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">A false colour composite of the study area</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img04/image4.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">An NDVI image of the study area</figcaption><p></p>
</figure>
</div>
</section>
<section id="creating-a-band-set" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="creating-a-band-set"><span class="header-section-number">5.4.3</span> Creating a Band set</h3>
<p>The next step is to create a band set.</p>
<ul>
<li>From the menu bar, select <strong>SCP</strong> -&gt; <strong>Band set</strong>.</li>
</ul>
<p><img src="img04/image5.jpg" class="img-fluid" width="319"></p>
<p>Band set dialog window appears.</p>
<ul>
<li><p>From the <strong>Single band list</strong>, click on band 2, 3, 4 and 8.</p></li>
<li><p>Click on the <strong>plus</strong> button.</p></li>
<li><p>For <strong>Wavelength quick setting</strong>, Select Sentinel-2 .</p></li>
</ul>
<p>Your screen should look similar to the figure below.</p>
<p><img src="img04/image6.jpg" class="img-fluid"></p>
<p>As you can see, the layers are seen under Band Set 1 (e.g.&nbsp;Band 2 - Blue (10 m)). Make sure the bands are in the right order and ascending.</p>
<ul>
<li>Click on <strong>Run</strong> button.</li>
</ul>
</section>
<section id="digitsing-training-samples" class="level3" data-number="5.4.4">
<h3 data-number="5.4.4" class="anchored" data-anchor-id="digitsing-training-samples"><span class="header-section-number">5.4.4</span> Digitsing training samples</h3>
<p>All supervised classification methods required prior identification of training samples, also refer to as region of interest (ROI). High quality training data is necessary to get good land cover product results. In the most ideal situation, training data is collected in the field by visiting each of the land cover types to be mapped and collecting attributes. When field collection is not an option, the second best choice is to digitise training data from high resolution colour composite images.</p>
<p>Figure below shows the false colour composite image of the study area and the training samples for the nine land cover types.</p>
<p><img src="img04/image34.jpg" class="img-fluid"></p>
<p>In this section, you will learn how to digitise training samples with the help of the colour composite and NDVI images created in the earlier section.</p>
<ul>
<li>From the icon bar, click on the icon marks in red.</li>
</ul>
<p><img src="img04/image7.jpg" class="img-fluid" width="370"></p>
<p>Notice that <strong>SCP &amp; Dock</strong> panel is added on the left hand panel of QGIS.</p>
<p>By default, the Home tab is selected.</p>
<ul>
<li>Click on the <strong>Training input</strong> tab.</li>
</ul>
<p><img src="img04/image8.jpg" class="img-fluid" width="356"></p>
<p>The panel should look similar to the figure below.</p>
<p><img src="img04/image9.jpg" class="img-fluid" width="395"></p>
<p>Next, you must create a file where the ROIs can be saved.</p>
<ul>
<li>At the SCP &amp; Dock panel, click on the second icon button located at the top level.</li>
</ul>
<p><img src="img04/image10.jpg" class="img-fluid" width="362"></p>
<p>The <strong>Create SCP training input</strong> dialog window open.</p>
<ul>
<li>Navigate to the data sub-folder (i.e.&nbsp;RSdata), called the output file <code>YT_train</code>.</li>
</ul>
<p><img src="img04/image11.jpg" class="img-fluid" width="491"></p>
<ul>
<li>When you are ready, click on <strong>Save</strong> button.</li>
</ul>
<p>Notice that a temporary layer called <code>YT_train</code> has been add onto Layer panel. Also note that Training input layer is <code>YT_train.scp</code>.</p>
<p><img src="img04/image12.jpg" class="img-fluid" width="361"></p>
<p>Before we start to create ROIs, let us understand two terms use in SCP, namely <strong>Classes</strong> and <strong>Macroclasses</strong>. In SCP, each ROI is identified by a Class ID (i.e.&nbsp;C ID), and each ROI is assigned to a land cover class through a Macroclass ID (i.e.&nbsp;MC ID). Macroclasses are composed of several materials having different spectral signatures; in order to achieve good classification results we should separate spectral signatures of different materials, even if belonging to the same macroclass. Thus,we are going to create several ROIs for each macro class (setting the same MCID, but assigning a different C ID to every ROI).</p>
<section id="defining-training-sample-by-using-polygon" class="level4" data-number="5.4.4.1">
<h4 data-number="5.4.4.1" class="anchored" data-anchor-id="defining-training-sample-by-using-polygon"><span class="header-section-number">5.4.4.1</span> Defining training sample by using polygon</h4>
<p>The first macroclass we are going to define is water body.</p>
<ul>
<li>From the layer, check to display the false colour composite image.</li>
</ul>
<p>Figure below shows the location of the water body sample site.</p>
<p><img src="img04/image13.jpg" class="img-fluid"></p>
<p>With SCP, a training sample be created by either manually drawing a polygon or with an automatic region growing algorithm. In this section, you will learn how to define a training sample by using polygon method.</p>
<ul>
<li>From <strong>SCP Working toolbar</strong>, click on <strong>Create a ROI polygon</strong> button.</li>
</ul>
<p><img src="img04/image14.jpg" class="img-fluid"></p>
<ul>
<li>On the View window, left click water sample site to define the ROI vertices and right click to define the last vertex closing the polygon.</li>
</ul>
<p>An orange semi-transparent polygon is displayed over the image, which is a temporary polygon (i.e.&nbsp;it is not saved in the Training input).</p>
<p>Once we are satisfy with the site, we can save it to the Training input.</p>
<ul>
<li><p>From <strong>SCP &amp; Dock</strong> panel, click on <strong>Training input</strong> tab.</p></li>
<li><p>In the <strong>ROI Signature list</strong> set <em>MC ID = 1</em> and <em>MC Info = Water body</em>; also set <em>C ID = 1</em> and <em>C Info = Water body</em>.</p></li>
</ul>
<p>Your screen should look similar to the figure below.</p>
<p><img src="img04/image15.jpg" class="img-fluid" width="387"></p>
<ul>
<li>Now click on Save temporary ROI to training input button <img src="img04/image16.jpg" width="21" height="25"> to save the ROI in the Training input.</li>
</ul>
<p>After a few seconds, the ROI is listed in the ROI Signature list and the spectral signature is calculated (because Signature was checked) as shown in the figure below.</p>
<p><img src="img04/image17.jpg" class="img-fluid" width="437"></p>
<p>As you can see, the C ID in ROI Signature list is automatically increased by 1. Saved ROI is displayed as a dark polygon in the map and the temporary ROI is removed.</p>
<p><strong>Be warned:</strong> The MC ID will not increase automatically. It is important for us to increase the number manually every time a new macroclass is used.</p>
<p><img src="img04/image18.jpg" class="img-fluid"></p>
<p>Also, in the ROI Signature list you can notice that the Type is <strong>R&amp;S</strong>, meaning that the ROI spectral signature was calculated and saved in the Training input.</p>
<p>You can also see in the tab Macroclasses that the first macroclass has been added to the table Macroclasses.</p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, define a training sample for Inland water as shown in the figure below.</p>
</blockquote>
<p><img src="img04/image19.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, define a training sample for Bare land as shown in the figure below.</p>
</blockquote>
<p><img src="img04/image20.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, define a training sample for Natural vegetation as shown in the figure below.</p>
</blockquote>
<p><img src="img04/image21.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, define a training sample for Managed vegetation as shown in the figure below.</p>
</blockquote>
<p><img src="img04/image22.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, define a training sample for Built-up 1 as shown in the figure below.</p>
</blockquote>
<p><img src="img04/image23.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, define a training sample for Built-up 2 as shown in the figure below.</p>
</blockquote>
<p><img src="img04/image24.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, define a training sample for Built-up 3 as shown in the figure below.</p>
</blockquote>
<p><img src="img04/image25.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, define a training sample for Impervious surfaces as shown in the figure below.</p>
</blockquote>
<p><img src="img04/image26.jpg" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Tip: You can have more than one polygon that represents the same class. In fact, you should typically have many polygons for each class. Many small ROIs are better than a few large ones (a few hundred pixels tops for each ROI). This can help account for the spectral variations in each land cover class. If you provide just one example of forest, it will be hard to recognize the variety of spectral signatures associated with that class. If you have multiple sub-classes under the same class (such as different tree species all being considered forest), your ROIs should reflect the full breadth of possible spectral signatures. You will find that you will need to adjust your training data a number of times (maybe many times!) in order to produce a quality classification. The actual classification part is just pressing a button, what most influences the accuracy of your results is the quality of your training data. Therefore, make sure to take your time when collecting ROIs. The amount of ROIs for each class should be proportional to the total area of that class in the image. If you have more forest than water, then you should have more ROIs for forest than you have for water.</p>
</blockquote>
</section>
</section>
<section id="assessing-the-spectral-signatures" class="level3" data-number="5.4.5">
<h3 data-number="5.4.5" class="anchored" data-anchor-id="assessing-the-spectral-signatures"><span class="header-section-number">5.4.5</span> Assessing the Spectral Signatures</h3>
<p>Spectral signatures are used by Classification Algorithms for labelling image pixels. Different materials may have similar spectral signatures (especially considering multispectral images) such as built-up and bare land. If spectral signatures used for classification are too similar, pixels could be misclassified because the algorithm is unable to discriminate correctly those signatures. Thus, it is useful to assess the Spectral Distance of signatures to find similar spectral signatures that must be removed. Of course the concept of distance varies according to the algorithm used for classification.</p>
<section id="spectral-signature-plot" class="level4" data-number="5.4.5.1">
<h4 data-number="5.4.5.1" class="anchored" data-anchor-id="spectral-signature-plot"><span class="header-section-number">5.4.5.1</span> Spectral Signature Plot</h4>
<p>In SCP, one can simply assess spectral signature similarity by displaying a signature plot.</p>
<ul>
<li>In order to display the signature plot, in the ROI Signature list highlight two or more spectral signatures (with click in the table), then click on <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/spectral_signature_plot.html#spectral-signature-plot">Spectral Signature Plot</a> <img src="img04/image32.jpg" class="img-fluid" width="31"> button.</li>
</ul>
<p>The Spectral Signature Plot appears.</p>
<p><img src="img04/image27.jpg" class="img-fluid"></p>
<p>In the plot we can see the line of each signature (with the color defined in the ROI &amp; Signature list), and the spectral range (minimum and maximum) of each band (i.e.&nbsp;the semi-transparent area colored like the signature line). The larger is the semi-transparent area of a signature, the higher is the standard deviation, and therefore the heterogeneity of pixels that composed that signature. Spectral similarity between spectral signatures is highlighted in orange in the Plot Signature list.</p>
<p>Figure below shows the Spectral Signature Plot of Natural vegetation and Managed vegetation. The figure reveals that there are significant overlapping of the signature values of Natural vegetation and Managed vegetation land cover classes.</p>
<p><img src="img04/image28.jpg" class="img-fluid"></p>
<p>Figure below shows the Spectral Signature Plot of Built-up 1, Built-up 2, Built-up 3 and Impervious surfaces land cover classes.</p>
<p><img src="img04/image29.jpg" class="img-fluid"></p>
<p>The figure reveals that there are significant overlapping of the signature values of these four land cover types. As a result, we should consider either by combining some of the highly similar land cover type or by increasing the number of more representative training samples.</p>
</section>
<section id="spectral-distance" class="level4" data-number="5.4.5.2">
<h4 data-number="5.4.5.2" class="anchored" data-anchor-id="spectral-distance"><span class="header-section-number">5.4.5.2</span> Spectral Distance</h4>
<p>Additionally, we can calculate the spectral distances of signatures (for more information see <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/remote_sensing.html#spectral-distance-definition">Spectral Distance</a>).</p>
<ul>
<li><p>Highlight two or more spectral signatures with click in the table Plot Signature list, then</p></li>
<li><p>At the Spectral signature plot window, click on Calculate spectral distance button located at the right of the panel.</p>
<p><img src="img04/image33.jpg" class="img-fluid" width="204"></p></li>
</ul>
<p>Distances will be calculated for each pair of signatures.</p>
<p>Now let us open the tab <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/spectral_signature_plot.html#spectral-distances">Spectral distances</a>.</p>
<ul>
<li>From the left of SCP: Spectral signature plot window, click on <strong>Spectral distance</strong> tab.</li>
</ul>
<p>Your screen should look similar to the screenshot below.</p>
<p><img src="img04/image31.jpg" class="img-fluid"></p>
<p>We can notice that similarity between signatures vary according to considered algorithm. For instance, two signatures can be very similar for <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/remote_sensing.html#spectra-angle-mapping-algorithm">Spectral Angle Mapping</a> (very low <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/remote_sensing.html#spectral-angle">Spectral Angle</a>), but quite distant for the <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/remote_sensing.html#max-likelihood-algorithm">Maximum Likelihood</a> (<a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/remote_sensing.html#jeffries-matusita-distance">Jeffries-Matusita Distance</a> value near 2). The similarity of signatures is affected by the similarity of materials (in relation to the number of spectral bands available); also, the way we create ROIs influences the signatures.</p>
</section>
<section id="spectral-details" class="level4" data-number="5.4.5.3">
<h4 data-number="5.4.5.3" class="anchored" data-anchor-id="spectral-details"><span class="header-section-number">5.4.5.3</span> Spectral details</h4>
<p>Another very useful plot in SCP: Spectral Signature Plot window is <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/spectral_signature_plot.html#signature-details-1">Signature details</a>.</p>
<ul>
<li>From the left of SCP: Spectral Signature Plot, click on Signature details tab.</li>
</ul>
<p>Your screen should look similar to the figure below.</p>
<p><img src="img04/image30.jpg" class="img-fluid"></p>
<p>Spectral signature values, standard deviation and other details such as the number of ROI pixels are displayed in the Signature details report.</p>
</section>
</section>
<section id="creating-a-classification-preview" class="level3" data-number="5.4.6">
<h3 data-number="5.4.6" class="anchored" data-anchor-id="creating-a-classification-preview"><span class="header-section-number">5.4.6</span> Creating a Classification Preview</h3>
<p>The classification process is based on collected ROIs (and spectral signatures thereof). It is useful to create a <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/working_toolbar.html#classification-preview">Classification preview</a> in order to assess the results (influenced by spectral signatures) before the final classification. In case the results are not good, we can collect more ROIs to better classify land cover.</p>
<blockquote class="blockquote">
<p>DIY: Before running a classification (or a preview), set the color of land cover classes that will be displayed in the classification raster.</p>
</blockquote>
<ul>
<li>In the ROI Signature list (page 27), double click the color (in the column Color) of each ROI to choose a representative color of each class. Also, we need to set the color for macroclasses in table Macroclasses.</li>
</ul>
<p>Now, we are read to perform Classification Preview.</p>
<p>Firstly, we need to select the classification algorithm. In this hands-on exercise we are going to use the <a href="https://semiautomaticclassificationmanual.readthedocs.io/en/latest/remote_sensing.html#max-likelihood-algorithm">Maximum Likelihood</a> algorithm.</p>
<ul>
<li>From menu bar, select SCP -&gt; Band Processing -&gt; Classification.</li>
</ul>
<p><img src="img04/image35.jpg" class="img-fluid" width="405"></p>
<p>The Classification dialog window appears.</p>
<p><img src="img04/image36.jpg" class="img-fluid"></p>
<ul>
<li><p>For <strong>Use</strong>, check <em>MC ID.</em></p></li>
<li><p>For Algorithm, select the Maximum Likelihood from the drop-down list.</p></li>
</ul>
<p>Next, return to QGIS window.</p>
<ul>
<li>From SCP Toolbar, set the preview size to 200.</li>
</ul>
<p><img src="img04/image37.jpg" class="img-fluid"></p>
<ul>
<li><p>Next, click on <strong>Activate classification preview pointer icon</strong> <img src="img04/image38.jpg" width="21" height="28">.</p></li>
<li><p>Hover you mouse over Kranji Camp, left-click a point of the image in the map.</p></li>
</ul>
<p>The classification process should be very fast, and the result is a classified square centered in clicked point as shown in the screenshot below.</p>
<p><img src="img04/image39.jpg" class="img-fluid"></p>
<p>Previews are temporary rasters (deleted after QGIS is closed) placed in a group named <code>Class_temp_group</code> in the QGIS panel Layers.</p>
<p><img src="img04/image39.jpg" class="img-fluid"></p>
<p>In general, it is good to perform a classification preview every time a ROI (or a spectral signature) is added to the ROI &amp; Signature list. Therefore, the phases Digitising training samples (or ROIs) and Creating a Classification Preview should be iterative and concurrent processes.</p>
</section>
<section id="generating-the-classification-output" class="level3" data-number="5.4.7">
<h3 data-number="5.4.7" class="anchored" data-anchor-id="generating-the-classification-output"><span class="header-section-number">5.4.7</span> Generating the Classification Output</h3>
<p>When we are happy with the classification preview review, it is time for us to perform the actual land cover classification of the whole image.</p>
<ul>
<li><p>From the Classificvation window, for Use, make sure that MC ID is checked.</p></li>
<li><p>Click on Run button.</p></li>
</ul>
<p>The Save classification output dialog window appears.</p>
<ul>
<li>Navigate to the data sub-folder of this project, give the output file an appropriate name (i.e.&nbsp;YT_ML). Notice that the output file will be saved in geotif file format.</li>
</ul>
<p>When the classification process is completed, a sound is played. At the same time, a land cover image called YT_ML will be added into Layers panel and display of view window of QGIS as shown in the figure below.</p>
<p><img src="img04/image40.jpg" class="img-fluid"></p>
</section>
<section id="assessing-the-classification-accuracy" class="level3" data-number="5.4.8">
<h3 data-number="5.4.8" class="anchored" data-anchor-id="assessing-the-classification-accuracy"><span class="header-section-number">5.4.8</span> Assessing the classification accuracy</h3>
<p>The last phase of a supervised classification is called classification accuracy assessment. In general, this phase consists of two steps. They are:</p>
<ol type="1">
<li><p>Digitise a new layer with ROIs and set again ROIs for the nine classes to have a reference ground. Warning: We cannot use the ROIs we used for the classification because you want to compare the classification with undependable training input.</p></li>
<li><p>Perform classification accuracy analysis by using Accuracy function of SCP.</p></li>
</ol>
<blockquote class="blockquote">
<p>DIY: Using the steps you had learned, digitise a new set of ROIs and name the file YT_test.</p>
</blockquote>
<p>Once the YT_test ROI is ready, we will perform the accuracy assessment analysis.</p>
<ul>
<li>From the menu bar of QGIS, click on <strong>SCP</strong> -&gt; <strong>Postprocessing</strong> -&gt; <strong>Accuracy</strong>.</li>
</ul>
<p><img src="img04/image41.jpg" class="img-fluid" width="410"></p>
<p>The Accuracy assessment dialog window appears.</p>
<ul>
<li><p>For <strong>Select the classification to assess</strong>, select the classified image (i.e.&nbsp;YT_ML) from the drop-down list (Note: It is always a good practice to click on the refresh button located at the end of the selection before clicking on the drop-down list. This is to ensure that the drop-down list provide the latest update.)</p></li>
<li><p>For <strong>Select the reference vector or raster</strong>, select the newly created test samples (i.e.&nbsp;YT_test) from the drop-down list (Note: It is always a good practice to click on the refresh button located at the end of the selection before clicking on the drop-down list. This is to ensure that the drop-down list provide the latest update.)</p></li>
<li><p>For <strong>Vector field</strong>, select MC_ID from the drop-down list.</p></li>
</ul>
<p>You screen should look similar to the screenshot below.</p>
<p><img src="img04/image42.jpg" class="img-fluid"></p>
<ul>
<li>Next, click on <strong>Run</strong> button.</li>
</ul>
<p>The <strong>Save error matrix raster output</strong> dialog window appears.</p>
<ul>
<li>Provide the output file a name (i.e.&nbsp;YT_ML).</li>
</ul>
<p><img src="img04/image43.jpg" class="img-fluid"></p>
<p>When you are ready,</p>
<ul>
<li>click on <strong>Save</strong> button.</li>
</ul>
<p>The Accuracy assessment report appears. It consists of three sub-section.</p>
<ol type="1">
<li>The long pair-wise error list.</li>
</ol>
<p><img src="img04/image44.jpg" class="img-fluid"></p>
<ol start="2" type="1">
<li>Confusion Matrix</li>
</ol>
<p><img src="img04/image45.jpg" class="img-fluid"></p>
<ol start="3" type="1">
<li>Kappa hat matix</li>
</ol>
<p><img src="img04/image46.jpg" class="img-fluid"></p>
<p>The output will tell you the accuracy for each class and the overall accuracy. The Kappa scale is from 0 to 1, 0 means the classification is not better than random, 1 means the classification is highly accurate. Refer to Lesson 10 slides for a comprehensive discussion of confusion matrix and Kappa statistics.</p>
</section>
</section>
<section id="references" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="references"><span class="header-section-number">5.5</span> References</h2>
<p><a href="https://earthobservatory.nasa.gov/features/LandCover/land_cover_2.php">How Scientists Differentiate Between Land Cover Types</a>.</p>
<p><a href="https://oceanservice.noaa.gov/facts/lclu.html">What is the difference between land cover and land use?</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Hands-on_03.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Processing and Visualising Landsat 8 Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Hands-on_05.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Unsupervised Satellite Image Classification for Urban Land Cover Mapping</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>